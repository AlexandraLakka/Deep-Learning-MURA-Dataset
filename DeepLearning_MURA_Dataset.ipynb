{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DeepLearning-MURA_Dataset.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AlexandraLakka/Deep-Learning-MURA-Dataset/blob/main/DeepLearning_MURA_Dataset.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pk3eRgbiS4vw"
      },
      "source": [
        "Mount Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q1acmgYOSmAH"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pfL3bu71S9Y-"
      },
      "source": [
        "Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8GdSYhF6S_m_"
      },
      "source": [
        "import gc\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "%matplotlib inline\n",
        "import cv2\n",
        "import os\n",
        "import pandas as pd\n",
        "from glob import glob\n",
        "import pickle\n",
        "from sklearn.utils import shuffle\n",
        "from skimage.transform import resize\n",
        "from tensorflow.keras.callbacks import TensorBoard\n",
        "import time\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "from tensorflow.keras import backend as K # Importing Keras backend (by default it is Tensorflow)\n",
        "from tensorflow.keras.callbacks import EarlyStopping # Callback for early stopping\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.layers import Activation, Input, Conv2D, Dense, Dropout, Flatten, MaxPooling2D, MaxPool2D, BatchNormalization, GaussianNoise # Layers to be used for building our model\n",
        "from tensorflow.keras.models import Sequential, Model # The class used to create a model\n",
        "from tensorflow.keras.optimizers import Adam, SGD\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.random import set_seed\n",
        "from tensorflow.keras.constraints import MinMaxNorm\n",
        "from tensorflow.keras.applications import DenseNet169, Xception, VGG16\n",
        "\n",
        "print(\"Tensorflow version \" + tf.__version__)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7hXvg43mTFBr"
      },
      "source": [
        "Read and save train data in dataframes from *train_image_paths.csv*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SQK8MZQMTKP9"
      },
      "source": [
        "data_path = '/content/drive/MyDrive/MURA-v1.1'\n",
        "train_images_csv = 'train_image_paths.csv'\n",
        "\n",
        "train_images_data = pd.read_csv(os.path.join(data_path, train_images_csv), header = None)\n",
        "train_images_data.columns = ['image_path']\n",
        "train_images_data['patient_id'] = train_images_data['image_path'].apply(lambda x : x.split('/')[3].replace('patient', ''))\n",
        "train_images_data['case'] = train_images_data['image_path'].apply(lambda x : x.split('/')[2])\n",
        "train_images_data['label'] = train_images_data['image_path'].apply(lambda x : x.split('/')[4].split('_')[1]).replace('negative', 0).replace('positive', 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xgpcz7Z1UO_K"
      },
      "source": [
        "Add to *image_path* column of dataframe the */content/drive/MyDrive/*, in order to be able to correctly read the images from the Drive "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ztTKp8n0UPKe"
      },
      "source": [
        "for i in range(0, len(train_images_data)):\n",
        "  tmp1 ='/content/drive/MyDrive/' + train_images_data['image_path'][i]\n",
        "  train_images_data['image_path'][i] = train_images_data['image_path'][i].replace(train_images_data['image_path'][i], tmp1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "shrHzXlnUrzX"
      },
      "source": [
        "Split original dataframe, based on the musculoskeletal category"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PSTnYSscUofk"
      },
      "source": [
        "#run for the first time to later create the part CSVs\n",
        "train_images_elbow = train_images_data.copy()\n",
        "train_images_finger = train_images_data.copy()\n",
        "train_images_forearm = train_images_data.copy()\n",
        "train_images_hand = train_images_data.copy()\n",
        "train_images_humerus = train_images_data.copy()\n",
        "train_images_shoulder = train_images_data.copy()\n",
        "train_images_wrist = train_images_data.copy()\n",
        "\n",
        "for i in range(0, len(train_images_elbow)):\n",
        "  if not ('XR_ELBOW') in train_images_elbow['image_path'][i]:\n",
        "    train_images_elbow.drop(i, inplace=True)\n",
        "\n",
        "for i in range(0, len(train_images_finger)):\n",
        "  if not ('XR_FINGER') in train_images_finger['image_path'][i]:\n",
        "    train_images_finger.drop(i, inplace=True)\n",
        "\n",
        "for i in range(0, len(train_images_forearm)):\n",
        "  if not ('XR_FOREARM') in train_images_forearm['image_path'][i]:\n",
        "    train_images_forearm.drop(i, inplace=True)\n",
        "\n",
        "for i in range(0, len(train_images_hand)):\n",
        "  if not ('XR_HAND') in train_images_hand['image_path'][i]:\n",
        "    train_images_hand.drop(i, inplace=True)\n",
        "\n",
        "for i in range(0, len(train_images_humerus)):\n",
        "  if not ('XR_HUMERUS') in train_images_humerus['image_path'][i]:\n",
        "    train_images_humerus.drop(i, inplace=True)    \n",
        "\n",
        "for i in range(0, len(train_images_shoulder)):\n",
        "  if not ('XR_SHOULDER') in train_images_shoulder['image_path'][i]:\n",
        "    train_images_shoulder.drop(i, inplace=True)   \n",
        "\n",
        "for i in range(0, len(train_images_wrist)):\n",
        "  if not ('XR_WRIST') in train_images_wrist['image_path'][i]:\n",
        "    train_images_wrist.drop(i, inplace=True)       "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d2gHxn0kVhdx"
      },
      "source": [
        "Save training datasets to Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DllblW0sVhqH"
      },
      "source": [
        "train_images_elbow.to_csv('/content/drive/MyDrive/Colab Notebooks/Test_Project/CSVs_binary/test_csvs/XR_ELBOW_csv.csv', index=False)\n",
        "train_images_finger.to_csv('/content/drive/MyDrive/Colab Notebooks/Test_Project/CSVs_binary/test_csvs/XR_FINGER_csv.csv', index=False)\n",
        "train_images_forearm.to_csv('/content/drive/MyDrive/Colab Notebooks/Test_Project/CSVs_binary/test_csvs/XR_FOREARM_csv.csv', index=False)\n",
        "train_images_hand.to_csv('/content/drive/MyDrive/Colab Notebooks/Test_Project/CSVs_binary/test_csvs/XR_HAND_csv.csv', index=False)\n",
        "train_images_humerus.to_csv('/content/drive/MyDrive/Colab Notebooks/Test_Project/CSVs_binary/test_csvs/XR_HUMERUS_csv.csv', index=False)\n",
        "train_images_shoulder.to_csv('/content/drive/MyDrive/Colab Notebooks/Test_Project/CSVs_binary/test_csvs/XR_SHOULDER_csv.csv', index=False)\n",
        "train_images_wrist.to_csv('/content/drive/MyDrive/Colab Notebooks/Test_Project/CSVs_binary/test_csvs/XR_WRIST_csv.csv', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-7hkHZJgWHi9"
      },
      "source": [
        "Read and save validation data in dataframes from *valid_image_paths.csv*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dS2wXvIIWHqz"
      },
      "source": [
        "val_images_csv = 'valid_image_paths.csv'\n",
        "val_images_data = pd.read_csv(os.path.join(data_path, val_images_csv), header = None)\n",
        "val_images_data.columns = ['image_path']\n",
        "val_images_data['patient_id'] = val_images_data['image_path'].apply(lambda x : x.split('/')[3].replace('patient', ''))\n",
        "val_images_data['case'] = val_images_data['image_path'].apply(lambda x : x.split('/')[2])\n",
        "val_images_data['label'] = val_images_data['image_path'].apply(lambda x : x.split('/')[4].split('_')[1]).replace('negative', 0).replace('positive', 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mBL5CLP-WZwk"
      },
      "source": [
        "Add to *image_path* column of dataframe the */content/drive/MyDrive/*, in order to be able to correctly read the images from the Drive "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pS84P1uiWZ3w"
      },
      "source": [
        "for i in range(0, len(val_images_data)):\n",
        "  tmp ='/content/drive/MyDrive/' + val_images_data['image_path'][i]\n",
        "  val_images_data['image_path'][i] = val_images_data['image_path'][i].replace(val_images_data['image_path'][i], tmp)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T-95v7f8WfI6"
      },
      "source": [
        "Split original dataframe, based on the musculoskeletal category"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3NKNrkbaWfO7"
      },
      "source": [
        "#run for the first time to later create the part CSVs\n",
        "val_images_elbow = val_images_data.copy()\n",
        "val_images_finger = val_images_data.copy()\n",
        "val_images_forearm = val_images_data.copy()\n",
        "val_images_hand = val_images_data.copy()\n",
        "val_images_humerus = val_images_data.copy()\n",
        "val_images_shoulder = val_images_data.copy()\n",
        "val_images_wrist = val_images_data.copy()\n",
        "\n",
        "for i in range(0, len(val_images_elbow)):\n",
        "  if not ('XR_ELBOW') in val_images_elbow['image_path'][i]:\n",
        "    val_images_elbow.drop(i, inplace=True)\n",
        "\n",
        "for i in range(0, len(val_images_finger)):\n",
        "  if not ('XR_FINGER') in val_images_finger['image_path'][i]:\n",
        "    val_images_finger.drop(i, inplace=True)\n",
        "\n",
        "for i in range(0, len(val_images_forearm)):\n",
        "  if not ('XR_FOREARM') in val_images_forearm['image_path'][i]:\n",
        "    val_images_forearm.drop(i, inplace=True)\n",
        "\n",
        "for i in range(0, len(val_images_hand)):\n",
        "  if not ('XR_HAND') in val_images_hand['image_path'][i]:\n",
        "    val_images_hand.drop(i, inplace=True)\n",
        "\n",
        "for i in range(0, len(val_images_humerus)):\n",
        "  if not ('XR_HUMERUS') in val_images_humerus['image_path'][i]:\n",
        "    val_images_humerus.drop(i, inplace=True)    \n",
        "\n",
        "for i in range(0, len(val_images_shoulder)):\n",
        "  if not ('XR_SHOULDER') in val_images_shoulder['image_path'][i]:\n",
        "    val_images_shoulder.drop(i, inplace=True)   \n",
        "\n",
        "for i in range(0, len(val_images_wrist)):\n",
        "  if not ('XR_WRIST') in val_images_wrist['image_path'][i]:\n",
        "    val_images_wrist.drop(i, inplace=True)       "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bJU4kUCEWslz"
      },
      "source": [
        "Save training datasets to Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZE6Ub4FsWs2J"
      },
      "source": [
        "val_images_elbow.to_csv('/content/drive/MyDrive/Colab Notebooks/Test_Project/CSVs_binary/validation_csvs/XR_ELBOW_csv.csv', index=False)\n",
        "val_images_finger.to_csv('/content/drive/MyDrive/Colab Notebooks/Test_Project/CSVs_binary/validation_csvs/XR_FINGER_csv.csv', index=False)\n",
        "val_images_forearm.to_csv('/content/drive/MyDrive/Colab Notebooks/Test_Project/CSVs_binary/validation_csvs/XR_FOREARM_csv.csv', index=False)\n",
        "val_images_hand.to_csv('/content/drive/MyDrive/Colab Notebooks/Test_Project/CSVs_binary/validation_csvs/XR_HAND_csv.csv', index=False)\n",
        "val_images_humerus.to_csv('/content/drive/MyDrive/Colab Notebooks/Test_Project/CSVs_binary/validation_csvs/XR_HUMERUS_csv.csv', index=False)\n",
        "val_images_shoulder.to_csv('/content/drive/MyDrive/Colab Notebooks/Test_Project/CSVs_binary/validation_csvs/XR_SHOULDER_csv.csv', index=False)\n",
        "val_images_wrist.to_csv('/content/drive/MyDrive/Colab Notebooks/Test_Project/CSVs_binary/validation_csvs/XR_WRIST_csv.csv', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q0fsXyS-YFNL"
      },
      "source": [
        "Load train and validation dataframes from Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YnWan5PnYFVN"
      },
      "source": [
        "#read CSVs\n",
        "train_images_elbow = pd.read_csv(os.path.join('/content/drive/MyDrive/Colab Notebooks/Test_Project/CSVs_binary/test_csvs', 'XR_ELBOW_csv.csv'))\n",
        "train_images_finger = pd.read_csv(os.path.join('/content/drive/MyDrive/Colab Notebooks/Test_Project/CSVs_binary/test_csvs', 'XR_FINGER_csv.csv'))\n",
        "train_images_forearm= pd.read_csv(os.path.join('/content/drive/MyDrive/Colab Notebooks/Test_Project/CSVs_binary/test_csvs', 'XR_FOREARM_csv.csv'))\n",
        "train_images_hand = pd.read_csv(os.path.join('/content/drive/MyDrive/Colab Notebooks/Test_Project/CSVs/test_csvs', 'XR_HAND_csv.csv'))\n",
        "train_images_humerus = pd.read_csv(os.path.join('/content/drive/MyDrive/Colab Notebooks/Test_Project/CSVs/test_csvs', 'XR_HUMERUS_csv.csv'))\n",
        "train_images_shoulder = pd.read_csv(os.path.join('/content/drive/MyDrive/Colab Notebooks/Test_Project/CSVs_binary/test_csvs', 'XR_SHOULDER_csv.csv'))\n",
        "train_images_wrist = pd.read_csv(os.path.join('/content/drive/MyDrive/Colab Notebooks/Test_Project/CSVs_binary/test_csvs', 'XR_WRIST_csv.csv'))\n",
        "\n",
        "val_images_elbow = pd.read_csv(os.path.join('/content/drive/MyDrive/Colab Notebooks/Test_Project/CSVs_binary/validation_csvs', 'XR_ELBOW_csv.csv'))\n",
        "val_images_finger = pd.read_csv(os.path.join('/content/drive/MyDrive/Colab Notebooks/Test_Project/CSVs_binary/validation_csvs', 'XR_FINGER_csv.csv'))\n",
        "val_images_forearm= pd.read_csv(os.path.join('/content/drive/MyDrive/Colab Notebooks/Test_Project/CSVs_binary/validation_csvs', 'XR_FOREARM_csv.csv'))\n",
        "val_images_hand = pd.read_csv(os.path.join('/content/drive/MyDrive/Colab Notebooks/Test_Project/CSVs/validation_csvs', 'XR_HAND_csv.csv'))\n",
        "val_images_humerus = pd.read_csv(os.path.join('/content/drive/MyDrive/Colab Notebooks/Test_Project/CSVs/validation_csvs', 'XR_HUMERUS_csv.csv'))\n",
        "val_images_shoulder = pd.read_csv(os.path.join('/content/drive/MyDrive/Colab Notebooks/Test_Project/CSVs/validation_csvs', 'XR_SHOULDER_csv.csv'))\n",
        "val_images_wrist = pd.read_csv(os.path.join('/content/drive/MyDrive/Colab Notebooks/Test_Project/CSVs_binary/validation_csvs', 'XR_WRIST_csv.csv'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9QQ0S14XYXfv"
      },
      "source": [
        "Shuffle dataframes so that the labels are in random order and the model cannot learn from that(this code was executed for all the different dataframes created)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LG5Le0Z3YXoZ"
      },
      "source": [
        "train_images_humerus = shuffle(train_images_humerus)\n",
        "train_images_humerus = train_images_humerus.reset_index(drop=True)\n",
        "\n",
        "val_images_humerus = shuffle(val_images_humerus)\n",
        "val_images_humerus = val_images_humerus.reset_index(drop=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wqaEQOTbZ_Sm"
      },
      "source": [
        "Create X_train from *image_path* in train datasets. All images were resized to have size 320x320 and turn images to grayscale(an attempt was made to store images with 3 channels, however that failed due to RAM constraints)\n",
        "[The process was repeated for all dataset(each time changed the name of the dataframe variable)]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6h0Fq6LmZ-cf"
      },
      "source": [
        "IMG_SIZE = 320\n",
        "X_train = np.empty((len(train_images_humerus), IMG_SIZE, IMG_SIZE, 1), dtype=np.float32)\n",
        "for i in range(0,len(train_images_humerus)):\n",
        "  image = cv2.imread(train_images_humerus['image_path'][i])\n",
        "  #print(train_images_hand['image_path'][i])\n",
        "  image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "  image = resize(image, output_shape=(IMG_SIZE, IMG_SIZE, 1), preserve_range=True)\n",
        "  X_train[i] = image"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-OBpHcRqbQpe"
      },
      "source": [
        "Create Y_train from *label* in train datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HcJ7NH9QbQxF"
      },
      "source": [
        "Y_train = np.empty(len(train_images_humerus), dtype=np.float32)\n",
        "for i in range(0,len(train_images_humerus)):\n",
        "  Y_train[i] = train_images_humerus['label'][i]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ufn3c18Vbdyv"
      },
      "source": [
        "Store X_train, Y_train as pickles in Drive, in order to avoid re-transforming the images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f47UxNgubd5-"
      },
      "source": [
        "pickle_out = open(\"/content/drive/MyDrive/Colab Notebooks/Test_Project/pickle/XR_HUMERUS/X_train_shuffled_rgb.pickle\", \"wb\") \n",
        "pickle.dump(X_train, pickle_out)\n",
        "pickle_out.close()\n",
        "\n",
        "pickle_out = open(\"/content/drive/MyDrive/Colab Notebooks/Test_Project/pickle/XR_HUMERUS/Y_train_shuffled_rgb.pickle\", \"wb\")\n",
        "pickle.dump(Y_train, pickle_out)\n",
        "pickle_out.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GK7bT7Yob0PG"
      },
      "source": [
        "Create X_val from *image_path* in validation datasets. All images were resized to have size 320x320 and turn images to grayscale(an attempt was made to store images with 3 channels, however that failed due to RAM constraints)[The process was repeated for all dataset(each time changed the name of the dataframe variable)]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zpxhCzn8b0WU"
      },
      "source": [
        "X_val = np.empty((len(val_images_humerus), IMG_SIZE, IMG_SIZE, 1), dtype=np.float32)\n",
        "for i in range(0,len(val_images_humerus)):\n",
        "  image = cv2.imread(val_images_humerus['image_path'][i])\n",
        "  image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "  image = resize(image, output_shape=(IMG_SIZE, IMG_SIZE, 1), preserve_range=True)\n",
        "  X_val[i] = image"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Rvai9Rpb8g5"
      },
      "source": [
        "Create Y_val from *label* in validation datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aiuLIqY2b8nr"
      },
      "source": [
        "Y_val = np.empty(len(val_images_humerus), dtype=np.float32)\n",
        "for i in range(0,len(val_images_humerus)):\n",
        "  Y_val[i] = val_images_humerus['label'][i]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RIsFX7qjcKv_"
      },
      "source": [
        "Store X_val, Y_val as pickles in Drive, in order to avoid re-transforming the images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d49tjC0ecK1V"
      },
      "source": [
        "pickle_out = open(\"/content/drive/MyDrive/Colab Notebooks/Test_Project/pickle/XR_HUMERUS/X_val_shuffled_rgb.pickle\", \"wb\") \n",
        "pickle.dump(X_val, pickle_out)\n",
        "pickle_out.close()\n",
        "\n",
        "pickle_out = open(\"/content/drive/MyDrive/Colab Notebooks/Test_Project/pickle/XR_HUMERUS/Y_val_shuffled_rgb.pickle\", \"wb\")\n",
        "pickle.dump(Y_val, pickle_out)\n",
        "pickle_out.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TmxUuFwwc6R-"
      },
      "source": [
        "Load X_train, Y_train, X_val, Y_val from Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tFQ74vc9c6X6"
      },
      "source": [
        "X_train = pickle.load(open('/content/drive/MyDrive/Colab Notebooks/Test_Project/pickle/XR_HUMERUS/X_train_shuffled.pickle', 'rb'))\n",
        "Y_train = pickle.load(open('/content/drive/MyDrive/Colab Notebooks/Test_Project/pickle/XR_HUMERUS/Y_train_shuffled.pickle', 'rb'))\n",
        "\n",
        "X_val = pickle.load(open('/content/drive/MyDrive/Colab Notebooks/Test_Project/pickle/XR_HUMERUS/X_val_shuffled.pickle', 'rb'))\n",
        "Y_val = pickle.load(open('/content/drive/MyDrive/Colab Notebooks/Test_Project/pickle/XR_HUMERUS/Y_val_shuffled.pickle', 'rb'))\n",
        "\n",
        "#turn to int, as the values are stored as flow\n",
        "Y_train = Y_train.astype(int)\n",
        "Y_val = Y_val.astype(int)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HRZFom9UdxMl"
      },
      "source": [
        "Normalize images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S-o95-yVdxUS"
      },
      "source": [
        "X_train /= 255\n",
        "X_val /= 255"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e4Vo1qNGe4NZ"
      },
      "source": [
        "Set batch size and epochs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h7QncwdBe46B"
      },
      "source": [
        "batch_size = 32\n",
        "epochs = 30"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LzthBcjUfCOt"
      },
      "source": [
        "VGG16(For the pretrained models, 3-channel images had to be used, however the model could only be tested for HUMERUS, since the process of resizing the images could not be performed on the majority of the categories - rejected)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q8VTjj8bfCWk"
      },
      "source": [
        "base_model = VGG16(\n",
        "    weights='imagenet',  # Load weights pre-trained on ImageNet.\n",
        "    input_shape=(320, 320, 3),\n",
        "    include_top=False)  # Do not include the ImageNet classifier at the top.\n",
        "\n",
        "base_model.trainable = False # Freeze training of pre-trained model\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(base_model)\n",
        "model.add(Flatten(input_shape=base_model.output_shape[1:]))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.compile(Adam(learning_rate=0.0001),loss='binary_crossentropy',metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VY0Tx0vnf-TS"
      },
      "source": [
        "DenseNet169(For the pretrained models, 3-channel images had to be used, however the model could only be tested for HUMERUS, since the process of resizing the images could not be performed on the majority of the categories - rejected)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hrOsPBhuf-aG"
      },
      "source": [
        "base_model = DenseNet169(\n",
        "    weights='imagenet',  # Load weights pre-trained on ImageNet.\n",
        "    input_shape=(320, 320, 3),\n",
        "    include_top=False)  # Do not include the ImageNet classifier at the top.\n",
        "\n",
        "base_model.trainable = False # Freeze training of pre-trained model\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(base_model)\n",
        "model.add(Flatten(input_shape=base_model.output_shape[1:]))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.compile(Adam(learning_rate=0.0001),loss='binary_crossentropy',metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lsqkDksAgmHv"
      },
      "source": [
        "Model made from scratch - Final version(accepted solution)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6XQab3yagmPT"
      },
      "source": [
        "# initializer = tf.keras.initializers.GlorotUniform() -> Use Glorot Uniform to initialize weights : rejected\n",
        "#initializer = tf.keras.initializers.GlorotNormal() -> Use Glorot Normal to initialize weights : rejected\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Input(shape=X_train.shape[1:]))\n",
        "\n",
        "model.add(Conv2D(16, (7, 7)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(BatchNormalization(momentum=0.99))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Conv2D(32, (5, 5), kernel_constraint=MinMaxNorm(min_value=0.0, max_value=1.0, rate=1.0, axis=0)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(BatchNormalization(momentum=0.99))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "model.add(Conv2D(64, (5, 5), kernel_constraint=MinMaxNorm(min_value=0.0, max_value=1.0, rate=1.0, axis=0)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(BatchNormalization(momentum=0.99))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Conv2D(64, (3, 3), kernel_constraint=MinMaxNorm(min_value=0.0, max_value=1.0, rate=1.0, axis=0)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(BatchNormalization(momentum=0.99))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "model.add(Conv2D(128, (3, 3), kernel_constraint=MinMaxNorm(min_value=0.0, max_value=1.0, rate=1.0, axis=0)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(BatchNormalization(momentum=0.99))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Conv2D(128, (3, 3), kernel_constraint=MinMaxNorm(min_value=0.0, max_value=1.0, rate=1.0, axis=0)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(BatchNormalization(momentum=0.99))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(GaussianNoise(0.2))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.compile(Adam(learning_rate=0.0001),loss='binary_crossentropy',metrics=['accuracy'])    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gfuAPVGZhsWO"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DZ8EldsR1scO"
      },
      "source": [
        "Create log of training results to check anytime on TensorBoard "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Hm-Wgjz1maJ"
      },
      "source": [
        "NAME = \"MURA-XR-SHOULDER-attempt-1-Adam-0.0001-Noise-0.2-1x16-1x32-2x64-2x128-EarlyStopping(val_loss)-{}\".format(int(time.time()))\n",
        "tensorboard = TensorBoard(log_dir='/content/drive/MyDrive/Colab Notebooks/logs/{}'.format(NAME))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "omF2sgao17T0"
      },
      "source": [
        "Use Early Stopping for validation loss with patience=10"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XDVC633T14Ig"
      },
      "source": [
        "callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MPOIzaDdiPAK"
      },
      "source": [
        "model.fit(x=X_train,\n",
        "          y=Y_train,\n",
        "                validation_data=(X_val, Y_val),\n",
        "                batch_size=batch_size,\n",
        "                epochs=30, callbacks=[tensorboard, cp_callback]\n",
        "        )\n",
        "\n",
        "'''\n",
        "# In the case of using generators to read and tranform data\n",
        "model1.fit(train_generator,\n",
        "                workers=8,\n",
        "                validation_data=val_generator,\n",
        "                epochs=10, callbacks=[tensorboard]\n",
        "        )\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o1ZY6Iu02HUT"
      },
      "source": [
        "Load TensorBoard to see results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cOwWPCLg2HbJ"
      },
      "source": [
        "%load_ext tensorboard"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jIJfkwPU2LBw"
      },
      "source": [
        "%tensorboard --logdir='/content/drive/MyDrive/Colab Notebooks/logs'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fFJLahejVSum"
      },
      "source": [
        "Make prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kJbU0FRWVS3t"
      },
      "source": [
        "case_study = '/content/drive/MyDrive/MURA-v1.1/valid/XR_HUMERUS/patient11186/study1_positive/'\n",
        "normal = 0\n",
        "abnormal = 0\n",
        "IMG_SIZE = 320\n",
        "\n",
        "for image in os.listdir(case_study):\n",
        "  image = case_study + image\n",
        "  #print(image)\n",
        "  image = cv2.imread(image)\n",
        "  image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "  image = cv2.resize(image, (IMG_SIZE, IMG_SIZE))\n",
        "  #print(image.shape)\n",
        "  image = image.reshape(-1, IMG_SIZE, IMG_SIZE, 1)\n",
        "  #print('Image shape: ', image.shape)\n",
        "  prediction = model.predict(image)\n",
        "  print (prediction)\n",
        "  if (int(prediction[0][0]) > 0.5):\n",
        "    abnormal += 1\n",
        "    print('Abnormal:' + str(abnormal))\n",
        "  else:\n",
        "    normal += 1\n",
        "    print('Normal:' + str(normal))\n",
        "\n",
        "if normal > abnormal:\n",
        "  print('This case study is normal!')\n",
        "elif abnormal > normal:\n",
        "  print('This case study is abnormal!')\n",
        "else: # if counters are equal\n",
        "  print('Reexamination is required!')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oL8Zs58u2nJ8"
      },
      "source": [
        "Attempts with ImageDataGenerator"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U2u9F-GxNU75"
      },
      "source": [
        "*flow_from_dataframe()* was initially used, to avoid creating and storing pickle files. Different dataframes were created, since the *y_col* required a string(instead of *1* or *0*,  *normal* or *abnormal* were used)[Rejected, beacause it was slow in *fit()* for the first epoch]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RhFOP3MnMRCU"
      },
      "source": [
        "train_datagen = ImageDataGenerator(rescale=1./255, horizontal_flip=True, brightness_range=[0.2,1.0])\n",
        "train_generator = train_datagen.flow_from_dataframe(train_images_hand, x_col='image_path',\n",
        "                                       y_col='label',target_size = (320, 320), \n",
        "                                       color_mode='rgb',\n",
        "                                       batch_size = batch_size, \n",
        "                                       class_mode = 'binary', \n",
        "                                       shuffle = True, validate_filenames=False)\n",
        "\n",
        "val_datagen = ImageDataGenerator(rescale=1./255)\n",
        "val_generator = val_datagen.flow_from_dataframe(val_images_hand, x_col='image_path',\n",
        "                                       y_col='label',target_size = (320, 320), \n",
        "                                       color_mode='rgb',\n",
        "                                       batch_size = batch_size, \n",
        "                                       class_mode = 'binary', \n",
        "                                       shuffle = True, validate_filenames=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8RQfDqBjO__O"
      },
      "source": [
        "Use instead *flow()*, with X_train, Y_train, X_val, Y_val"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mctVKCJzOYbC"
      },
      "source": [
        "train_datagen = ImageDataGenerator(rescale=1./255, horizontal_flip=True, brightness_range=[0.2,1.0])\n",
        "#train_datagen = ImageDataGenerator(horizontal_flip=True, brightness_range=[0.2,1.0])\n",
        "\n",
        "train_generator = train_datagen.flow(X_train, y=Y_train, \n",
        "                                       batch_size = batch_size,  \n",
        "                                       shuffle = True)\n",
        "\n",
        "val_datagen = ImageDataGenerator(rescale=1./255)\n",
        "val_generator = val_datagen.flow(\n",
        "            X_val,\n",
        "            y=Y_val,\n",
        "            batch_size=batch_size,\n",
        "            shuffle=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9V_CZdjZPVSJ"
      },
      "source": [
        "Try to use DataGenerator and normalize the data according to mean and standard deviation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IAyYVCiAPVaf"
      },
      "source": [
        "datagen = ImageDataGenerator(\n",
        "        featurewise_center=True,\n",
        "        featurewise_std_normalization= True)\n",
        "\n",
        "train_generator = datagen.flow(X_train, y=Y_train, \n",
        "                                       batch_size = batch_size,  \n",
        "                                       shuffle = True)\n",
        "\n",
        "sample_size=100\n",
        "raw_train_generator = ImageDataGenerator().flow(\n",
        "        X_train,Y_train, \n",
        "        batch_size=sample_size, \n",
        "        shuffle=False)\n",
        "\n",
        "# get data sample\n",
        "batch = raw_train_generator.next()\n",
        "data_sample = batch[0]\n",
        "\n",
        "image_generator = ImageDataGenerator(\n",
        "        featurewise_center=True,\n",
        "        featurewise_std_normalization= True)\n",
        "\n",
        "# fit generator to sample from training data\n",
        "image_generator.fit(data_sample)\n",
        "\n",
        "val_generator = image_generator.flow(\n",
        "            X_val,\n",
        "            y=Y_val,\n",
        "            batch_size=batch_size,\n",
        "            shuffle=False)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}